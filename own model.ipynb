{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 69107,
     "status": "ok",
     "timestamp": 1599565900311,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "3U_YZWiFS0VO",
    "outputId": "9a586dc3-ca30-4fe0-ae4f-8fbbe0c31b93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-1d88b4f4-f497-49f7-a47c-2411225e7d21\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-1d88b4f4-f497-49f7-a47c-2411225e7d21\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train2000.csv to train2000.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files \n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1262,
     "status": "ok",
     "timestamp": 1599565910291,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "73gGlln6TQzZ",
    "outputId": "13665f6d-6440-4696-c746-8c860c163a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                     index  ... answer_start  c_id\n",
      "0              0  56be85543aeaaa14008c9063  ...        269.0     0\n",
      "1              1  56be88473aeaaa14008c9080  ...        104.0     2\n",
      "2              2  56be892d3aeaaa14008c908c  ...        204.0     3\n",
      "3              3  56bf74d53aeaaa14008c965a  ...        101.0     3\n",
      "4              4  56bf76ef3aeaaa14008c9664  ...        148.0     4\n",
      "...          ...                       ...  ...          ...   ...\n",
      "1995        1995  56e1039be3433e1400422aa6  ...        103.0  2824\n",
      "1996        1996  56e1039be3433e1400422aa7  ...        149.0  2824\n",
      "1997        1997  56e104b7e3433e1400422acb  ...         43.0  2826\n",
      "1998        1998  56e10f57cd28a01900c674ff  ...          3.0  2827\n",
      "1999        1999  56e1156fe3433e1400422bb0  ...        112.0  2828\n",
      "\n",
      "[2000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import io   \n",
    "train= pd.read_csv(io.BytesIO(uploaded['train2000.csv'])) \n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2648,
     "status": "ok",
     "timestamp": 1599565920422,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "tfTzsaGqaSDG",
    "outputId": "459e5444-f9b3-4d31-b154-c8c13ff3111d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byJWd9QoZWic"
   },
   "outputs": [],
   "source": [
    "ques=train.question   # all questions\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_ques = [word_tokenize(i) for i in ques] #word tokenization of all questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6bSVjA7ZWmT"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "model= FastText(tokenized_ques, size=100, window=11, min_count=1,alpha=0.025, iter=100, workers=4,sg=1,cbow_mean=0,sorted_vocab=0) # training it with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Ep24uk9ZWpB"
   },
   "outputs": [],
   "source": [
    "paragra= train.context.unique()  # all unique paragraphs\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_para = [word_tokenize(i) for i in paragra] #word tokenization of all paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SV_7SitOZWrc"
   },
   "outputs": [],
   "source": [
    "model.build_vocab(tokenized_para, update=True)  # Update the vocabulary\n",
    "model.train(tokenized_para, total_examples=len(tokenized_para), epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RsdFz2EgZWyV"
   },
   "outputs": [],
   "source": [
    "# function to make sentence vectors from word vectors\n",
    "def sent_vectorizer(sent, model):\n",
    "    sent_vec =[]\n",
    "    numw = 0\n",
    "    for w in sent:\n",
    "        try:\n",
    "            if numw == 0:\n",
    "                sent_vec = model[w]\n",
    "            else:\n",
    "                sent_vec = np.add(sent_vec, model[w])\n",
    "            numw+=1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return np.asarray(sent_vec) / numw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1753,
     "status": "ok",
     "timestamp": 1599568175414,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "L8uU81dQZW3g",
    "outputId": "a469baf8-8c78-4888-f276-1c0fb9e45a70"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "paragraph=[]  # list of all unique paragraph vectors\n",
    "\n",
    "for sentence in tokenized_para:\n",
    "    paragraph.append(sent_vectorizer(sentence, model)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2143,
     "status": "ok",
     "timestamp": 1599568179578,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "TCWlf8f-ZW7J",
    "outputId": "eab0e6e3-c8b7-4d49-9e91-92a90a114d45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question=[]  # list of all question vectors\n",
    "for sentence in tokenized_ques:\n",
    "    question.append(sent_vectorizer(sentence, model))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2245,
     "status": "ok",
     "timestamp": 1599568183443,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "0GpuTz7iZXBo",
    "outputId": "87f4253d-518a-4e62-f158-1bc1dba34d80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "paraorigi=train.context # all paragraphs\n",
    "tokenized_paraoriginal = [word_tokenize(i) for i in paraorigi]\n",
    "print(len(tokenized_paraoriginal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2264,
     "status": "ok",
     "timestamp": 1599568187369,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "JVqL1LFmZXFn",
    "outputId": "8ddabaf2-7541-41fd-fb9d-d03fd6a30c3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "paraoriginal=[] # list of all paragraph vectors\n",
    "for sentence in tokenized_paraoriginal:\n",
    "    paraoriginal.append(sent_vectorizer(sentence, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Nx5lvNXZXHm"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def cosineValue(v1,v2):                  #compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7G9FeA9KNLns"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54508,
     "status": "ok",
     "timestamp": 1599568473131,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "vEHAJq-AZP55",
    "outputId": "7fcae0d9-d5be-4cb9-bddc-7ef6a1e4ff6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [04:36<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "73.3\n",
      "79.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# function  to find the accuracy of getting the correct paragraph out of the 3 and top 5 matched paragraphs \n",
    "count5=0   #  for top 5\n",
    "count3=0   #  for top 3\n",
    "for j in tqdm(range(len(question))):    #iterate over questions  # no. of questions=2000\n",
    "    ques1=[]\n",
    "    for i in range(len(paragraph)):     # iterate over paragraphs # no. of paragraph=1238\n",
    "         ques1.append(cosineValue (question[j], paragraph[i]))  # storing cosine value for a particular question with each paragraph\n",
    "    res = sorted(range(len(ques1)), key = lambda sub: ques1[sub])[-5:] #to store paragraph indices for top 5 cosine values\n",
    "    arr0=paragraph[res[0]]  # corresponding 5 paragraph vectors\n",
    "    arr1=paragraph[res[1]]\n",
    "    arr2=paragraph[res[2]]\n",
    "    arr3=paragraph[res[3]]\n",
    "    arr4=paragraph[res[4]]\n",
    "    \n",
    "    para=paraoriginal[j]  # original paragraph vector (paragraph vector corresponding to the question)\n",
    "\n",
    "    check0=para==arr0 #check whether the original vector is equal to one of the 5 vectors\n",
    "    check1=para==arr1\n",
    "    check2=para==arr2\n",
    "    check3=para==arr3\n",
    "    check4=para==arr4\n",
    "    if(check2.all() or check3.all() or check4.all() ): # for top 3\n",
    "        count3+=1\n",
    "    if(check0.all() or check1.all() or check2.all() or check3.all() or check4.all() ): # for top 5\n",
    "        count5+=1\n",
    "    \n",
    "print(\"\\n\")\n",
    "print((count3/len(question))*100)\n",
    "print((count5/len(question))*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvocu4oWZqFl"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "stop_words= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1660,
     "status": "ok",
     "timestamp": 1599568551888,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "ssQQOj6A5c-c",
    "outputId": "8f5c9972-e14c-4f90-8626-b3f1e19a1a8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# to make new vectors of questions by removing stopwords \n",
    "for i in range(len(ques)):\n",
    "    ques[i]=ques[i].lower()         # convert to lower case\n",
    "tokenized_ques = [word_tokenize(i) for i in ques]\n",
    "ques_new=[]\n",
    "for i in range(len(ques)):\n",
    "    filtered_sentence = [w for w in tokenized_ques[i] if not w in stop_words]  # storing words which are not stopwords\n",
    "\n",
    "    filtered_sentence = [] \n",
    "\n",
    "    for w in tokenized_ques[i]: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)   \n",
    "    ques_new.append(filtered_sentence)\n",
    "question_new=[]                         #  list of all new question vectors\n",
    "for sentence in ques_new:\n",
    "    question_new.append(sent_vectorizer(sentence, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3084,
     "status": "ok",
     "timestamp": 1599568557368,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "HZCsobvR5dH1",
    "outputId": "74ef1041-2e02-412a-8054-20de334ddbec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    " # same for all unique paragraph - removing stopwords\n",
    "for i in range(len(paragra)):\n",
    "    paragra[i]=paragra[i].lower()\n",
    "tokenized_para = [word_tokenize(i) for i in paragra]\n",
    "paragra_new=[]\n",
    "for i in range(len(paragra)):\n",
    "    filtered_sentence = [w for w in tokenized_para[i] if not w in stop_words] \n",
    "\n",
    "    filtered_sentence = [] \n",
    "\n",
    "    for w in tokenized_para[i]: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)   \n",
    "    paragra_new.append(filtered_sentence)\n",
    "paragraph_new=[]                            #  list of all new unique paragraph vectors\n",
    "for sentence in paragra_new:\n",
    "    paragraph_new.append(sent_vectorizer(sentence, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3237,
     "status": "ok",
     "timestamp": 1599568564411,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "BbrelUUJ5l_Q",
    "outputId": "b633db2f-73e3-423c-880e-974f8f2c6a43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#same for all paragraphs - removing stopwords\n",
    "for i in range(len(paraorigi)):\n",
    "    paraorigi[i]=paraorigi[i].lower()\n",
    "tokenized_paraoriginal = [word_tokenize(i) for i in paraorigi]\n",
    "paragraorigi_new=[]\n",
    "for i in range(len(paraoriginal)):\n",
    "    filtered_sentence = [w for w in tokenized_paraoriginal[i] if not w in stop_words] \n",
    "\n",
    "    filtered_sentence = [] \n",
    "\n",
    "    for w in tokenized_paraoriginal[i]: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)   \n",
    "    paragraorigi_new.append(filtered_sentence)\n",
    "paraoriginal_new=[]                               #  list of all new paragraph vectors\n",
    "for sentence in paragraorigi_new:\n",
    "    paraoriginal_new.append(sent_vectorizer(sentence, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 278471,
     "status": "ok",
     "timestamp": 1599568844476,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "IZv7bDev5mGM",
    "outputId": "5e84d8af-3bcf-4934-d9f9-418b2c8e8be3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [04:37<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "79.2\n",
      "84.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# same function  to find the accuracy but with questions and paragraphs after removing stopwords\n",
    "count3=0\n",
    "count5=0\n",
    "for j in tqdm(range(len(question_new))):\n",
    "    ques1=[]\n",
    "    for i in range(len(paragraph_new)):\n",
    "         ques1.append(cosineValue (question_new[j], paragraph_new[i]))\n",
    "    res = sorted(range(len(ques1)), key = lambda sub: ques1[sub])[-5:] \n",
    "    arr0=paragraph_new[res[0]]\n",
    "    arr1=paragraph_new[res[1]]\n",
    "    arr2=paragraph_new[res[2]]\n",
    "    arr3=paragraph_new[res[3]]\n",
    "    arr4=paragraph_new[res[4]]\n",
    "    para=paraoriginal_new[j]\n",
    "\n",
    "    check0=para==arr0\n",
    "    check1=para==arr1\n",
    "    check2=para==arr2\n",
    "    check3=para==arr3\n",
    "    check4=para==arr4\n",
    "\n",
    "    if(check2.all() or check3.all() or check4.all() ): # for top 3\n",
    "        count3+=1\n",
    "    if(check0.all() or check1.all() or check2.all() or check3.all() or check4.all() ): # for top 5\n",
    "        count5+=1\n",
    "    \n",
    "print(\"\\n\")\n",
    "print((count3/len(question))*100)\n",
    "print((count5/len(question))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2901,
     "status": "ok",
     "timestamp": 1599568865023,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "eLgOzcrY8Zpa",
    "outputId": "f5213690-868a-485d-801a-1fe637a27cd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1238 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "100%|██████████| 1238/1238 [00:01<00:00, 710.47it/s]\n"
     ]
    }
   ],
   "source": [
    " # for each paragraph, breaking the paragraph into sentences and storing the vector of each sentence   (after removing stopwords)\n",
    "paravectors=[] # contains list of parasentence_new[i] which is containing list of sentence vectors of the particular paragraph\n",
    "for i in tqdm(range(len(paragra))):\n",
    "    text=paragra[i]\n",
    "    a_list1 = nltk.tokenize.sent_tokenize(text)  # breaking the paragraph to sentences\n",
    "    tokenized_sents3 = [word_tokenize(j) for j in a_list1]\n",
    "    parasent=[]            \n",
    "    for i in range(len(tokenized_sents3)):\n",
    "        filtered_sentence = [w for w in tokenized_sents3[i] if not w in stop_words] \n",
    "        filtered_sentence = [] \n",
    "        for w in tokenized_sents3[i]: \n",
    "            if w not in stop_words: \n",
    "                filtered_sentence.append(w)   \n",
    "        parasent.append(filtered_sentence)    # storing each sentence after removing stopwords\n",
    "    parasentence_new=[]                    \n",
    "    for sentence in parasent:\n",
    "        parasentence_new.append(sent_vectorizer(sentence, model)) # contains list of sentence vectors of the particular paragraph\n",
    "    paravectors.append(parasentence_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKKu9IixHNjB"
   },
   "outputs": [],
   "source": [
    " # function which finds the accuracy of the most similar sentence in a given paragraph with a given question\n",
    "def cosineValue1(v1,parasentence_new):\n",
    "    cossimilar=[]\n",
    "    for i in range(len(parasentence_new)):\n",
    "        cossimilar.append(cosineValue(v1,parasentence_new[i]))\n",
    "    res1 = sorted(range(len(cossimilar)), key = lambda sub: cossimilar[sub])[-1:]\n",
    "    x= cossimilar[res1[0]]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1053122,
     "status": "ok",
     "timestamp": 1599569923461,
     "user": {
      "displayName": "Nilaya Agarwal",
      "photoUrl": "",
      "userId": "02698675958604519659"
     },
     "user_tz": -330
    },
    "id": "XvmM0MPYHOAe",
    "outputId": "6a17528a-9dcb-4993-d205-481439356133"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [17:31<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "81.0\n",
      "86.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# function  to find the accuracy of getting the correct paragraph (after considering only the most similar sentence in it) out of the 3 and top 5 matched paragraphs (and removing stopwords)\n",
    "count3=0\n",
    "count5=0\n",
    "for j in tqdm(range(len(question_new))):\n",
    "    ques1=[]\n",
    "    for i in range(len(paragraph_new)):\n",
    "         ques1.append(cosineValue1 (question_new[j],paravectors[i]))  # the parameters are the given question vector and list containing sentence vectors of a given paragraph\n",
    "    res = sorted(range(len(ques1)), key = lambda sub: ques1[sub])[-5:] \n",
    "    arr0=paragraph_new[res[0]]\n",
    "    arr1=paragraph_new[res[1]]\n",
    "    arr2=paragraph_new[res[2]]\n",
    "    arr3=paragraph_new[res[3]]\n",
    "    arr4=paragraph_new[res[4]]\n",
    "    para_j=paraoriginal_new[j]\n",
    "\n",
    "    check0=para_j==arr0\n",
    "    check1=para_j==arr1\n",
    "    check2=para_j==arr2\n",
    "    check3=para_j==arr3\n",
    "    check4=para_j==arr4\n",
    "    \n",
    "    if(check2.all() or check3.all() or check4.all() ): # for top 3\n",
    "        count3+=1\n",
    "    if(check0.all() or check1.all() or check2.all() or check3.all() or check4.all() ): # for top 5\n",
    "        count5+=1\n",
    "    \n",
    "print(\"\\n\")\n",
    "print((count3/len(question))*100)\n",
    "print((count5/len(question))*100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNQtK6YU3/fCEUyOFkDTgyl",
   "collapsed_sections": [],
   "name": "own model 2000.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
